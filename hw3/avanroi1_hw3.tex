\documentclass[11pt]{article}
\usepackage{amsgen,amsmath,amstext,amsbsy,amsopn,amssymb}
%\usepackage[dvips]{graphicx,color}
\usepackage{graphicx,color}
\usepackage{graphicx,color,bm}
\usepackage{epsfig}
\usepackage{enumerate}
\usepackage{float}

%\setlength{\oddsidemargin}{0.1 in} \setlength{\evensidemargin}{-0.1
%in} \setlength{\topmargin}{-0.6 in} \setlength{\textwidth}{6.5 in}
%\setlength{\textheight}{8.5 in} \setlength{\headsep}{0.75 in}
%\setlength{\parindent}{0 in} \setlength{\parskip}{0.1 in}

\textwidth 6.3in \textheight 8.8in \topmargin -0.5truein
\oddsidemargin .15truein
\parskip .1in
\renewcommand{\baselinestretch}{1.53}  % double spaced


\newcommand{\homework}[9]{
	\pagestyle{myheadings}
	\thispagestyle{plain}
	\newpage
	\setcounter{page}{1}
	\noindent
	\begin{center}
		\framebox{
			\vbox{\vspace{2mm}
				\hbox to 6.28in { {\bf Math531:~Regression - I  \hfill} }
				\vspace{6mm}
				\hbox to 6.28in { {\Large \hfill #1 (#2)  \hfill} }
				\vspace{6mm}
				\hbox to 6.28in { {\it Instructor: #3 \hfill} }
				\hbox to 6.28in { {\it Office hours: #4  \hfill #6}}
				\vspace{2mm}}
		}
	\end{center}
	\markboth{#1}{#1}
	\vspace*{4mm}
}

% ----------------------- MATH -------------------------
\def\av{\boldsymbol a}
\def\bv{\boldsymbol b}
\def\cv{\boldsymbol c}
\def\dv{\boldsymbol d}
\def\ev{\boldsymbol e}
\def\fv{\boldsymbol f}
\def\gv{\boldsymbol g}
\def\hv{\boldsymbol h}
\def\iv{\boldsymbol i}
\def\gv{\boldsymbol j}
\def\kv{\boldsymbol k}
\def\lv{\boldsymbol l}
\def\mv{\boldsymbol m}
\def\nv{\boldsymbol n}
\def\ov{\boldsymbol o}
\def\pv{\boldsymbol p}
\def\qv{\boldsymbol q}
\def\rv{\boldsymbol r}
\def\sv{\boldsymbol s}
\def\tv{\boldsymbol t}
\def\uv{\boldsymbol u}
\def\vv{\boldsymbol v}
\def\wv{\boldsymbol w}
\def\xv{\boldsymbol x}
\def\yv{\boldsymbol y}
\def\zv{\boldsymbol z}
\def\Av{\boldsymbol A}
\def\Bv{\boldsymbol B}
\def\Cv{\boldsymbol C}
\def\Dv{\boldsymbol D}
\def\Ev{\boldsymbol E}
\def\Fv{\boldsymbol F}
\def\Gv{\boldsymbol G}
\def\Hv{\boldsymbol H}
\def\Iv{\boldsymbol I}
\def\Gv{\boldsymbol J}
\def\Kv{\boldsymbol K}
\def\Lv{\boldsymbol L}
\def\Mv{\boldsymbol M}
\def\Nv{\boldsymbol N}
\def\Ov{\boldsymbol O}
\def\Pv{\boldsymbol P}
\def\Qv{\boldsymbol Q}
\def\Rv{\boldsymbol R}
\def\Sv{\boldsymbol S}
\def\Tv{\boldsymbol T}
\def\Uv{\boldsymbol U}
\def\Vv{\boldsymbol V}
\def\Wv{\boldsymbol W}
\def\Xv{\boldsymbol X}
\def\Yv{\boldsymbol Y}
\def\Zv{\boldsymbol Z}
\def\Abf{\mathbf A}
\def\Bbf{\mathbf B}
\def\Cbf{\mathbf C}
\def\Dbf{\mathbf D}
\def\Ebf{\mathbf E}
\def\Fbf{\mathbf F}
\def\Gbf{\mathbf G}
\def\Hbf{\mathbf H}
\def\Ibf{\mathbf I}
\def\Gbf{\mathbf J}
\def\Kbf{\mathbf K}
\def\Lbf{\mathbf L}
\def\Mbf{\mathbf M}
\def\Nbf{\mathbf N}
\def\Obf{\mathbf O}
\def\Pbf{\mathbf P}
\def\Qbf{\mathbf Q}
\def\Rbf{\mathbf R}
\def\Sbf{\mathbf S}
\def\Tbf{\mathbf T}
\def\Ubf{\mathbf U}
\def\Vbf{\mathbf V}
\def\Wbf{\mathbf W}
\def\Xbf{\mathbf X}
\def\Ybf{\mathbf Y}
\def\Jbf{\mathbf J}
\def\Zbf{\mathbf Z}
\def\Am{\mathrm A}
\def\Bm{\mathrm B}
\def\Cm{\mathrm C}
\def\Dm{\mathrm D}
\def\Em{\mathrm E}
\def\Fm{\mathrm F}
\def\Gm{\mathrm G}
\def\Hm{\mathrm H}
\def\Im{\mathrm I}
\def\Gm{\mathrm J}
\def\Km{\mathrm K}
\def\Lm{\mathrm L}
\def\Mm{\mathrm M}
\def\Nm{\mathrm N}
\def\Om{\mathrm O}
\def\Pm{\mathrm P}
\def\Qm{\mathrm Q}
\def\Rm{\mathrm R}
\def\Sm{\mathrm S}
\def\Tm{\mathrm T}
\def\Um{\mathrm U}
\def\mv{\mathrm V}
\def\Wm{\mathrm W}
\def\Xm{\mathrm X}
\def\Ym{\mathrm Y}
\def\Zm{\mathrm Z}
\newcommand{\Ac}{\mathcal{A}}
\newcommand{\Bc}{\mathcal{B}}
\newcommand{\Cc}{\mathcal{C}}
\newcommand{\Dc}{\mathcal{D}}
\newcommand{\Ec}{\mathcal{E}}
\newcommand{\Fc}{\mathcal{F}}
\newcommand{\Gc}{\mathcal{G}}
\newcommand{\Hc}{\mathcal{H}}
\newcommand{\Ic}{\mathcal{I}}
\newcommand{\Jc}{\mathcal{J}}
\newcommand{\Kc}{\mathcal{K}}
\newcommand{\Lc}{\mathcal{L}}
\newcommand{\Mc}{\mathcal{M}}
\newcommand{\Nc}{\mathcal{N}}
\newcommand{\Oc}{\mathcal{O}}
\newcommand{\Pc}{\mathcal{P}}
\newcommand{\Qc}{\mathcal{Q}}
\newcommand{\Rc}{\mathcal{R}}
\newcommand{\Sc}{\mathcal{S}}
\newcommand{\Tc}{\mathcal{T}}
\newcommand{\Uc}{\mathcal{U}}
\newcommand{\Vc}{\mathcal{V}}
\newcommand{\Wc}{\mathcal{W}}
\newcommand{\Xc}{\mathcal{X}}
\newcommand{\Yc}{\mathcal{Y}}
\newcommand{\Zc}{\mathcal{Z}}
\newcommand{\alphav}{\mbox{\boldmath{$\alpha$}}}
\newcommand{\betav}{\mbox{\boldmath{$\beta$}}}
\newcommand{\gammav}{\mbox{\boldmath{$\gamma$}}}
\newcommand{\deltav}{\mbox{\boldmath{$\delta$}}}
\newcommand{\epsilonv}{\mbox{\boldmath{$\epsilon$}}}
\newcommand{\zetav}{\mbox{\boldmath$\zeta$}}
\newcommand{\etav}{\mbox{\boldmath{$\eta$}}}
\newcommand{\iotav}{\mbox{\boldmath{$\iota$}}}
\newcommand{\kappav}{\mbox{\boldmath{$\kappa$}}}
\newcommand{\lambdav}{\mbox{\boldmath{$\lambda$}}}
\newcommand{\muv}{\mbox{\boldmath{$\mu$}}}
\newcommand{\nuv}{\mbox{\boldmath{$\nu$}}}
\newcommand{\xiv}{\mbox{\boldmath{$\xi$}}}
\newcommand{\omicronv}{\mbox{\boldmath{$\omicron$}}}
\newcommand{\piv}{\mbox{\boldmath{$\pi$}}}
\newcommand{\rhov}{\mbox{\boldmath{$\rho$}}}
\newcommand{\sigmav}{\mbox{\boldmath{$\sigma$}}}
\newcommand{\tauv}{\mbox{\boldmath{$\tau$}}}
\newcommand{\upsilonv}{\mbox{\boldmath{$\upsilon$}}}
\newcommand{\phiv}{\mbox{\boldmath{$\phi$}}}
\newcommand{\varphiv}{\mbox{\boldmath{$\varphi$}}}
\newcommand{\chiv}{\mbox{\boldmath{$\chi$}}}
\newcommand{\psiv}{\mbox{\boldmath{$\psi$}}}
\newcommand{\omegav}{\mbox{\boldmath{$\omega$}}}
\newcommand{\Sigmav}{\mbox{\boldmath{$\Sigma$}}}
\newcommand{\Lambdav}{\mbox{\boldmath{$\Lambda$}}}
\newcommand{\Deltav}{\mbox{\boldmath{$\Delta$}}}
\newcommand{\Omegav}{\mbox{\boldmath{$\Omega$}}}
\newcommand{\varepsilonv}{\mbox{\boldmath{$\varepsilon$}}}

\newcommand{\eps}{\varepsilon}
\newcommand{\epsv}{\mbox{\boldmath{$\varepsilon$}}}

\def\1v{\mathbf 1}
\def\0v{\mathbf 0}
\def\Id{\mathbf I} % identity matrix
\newcommand{\ind}[1]{\mathbbm{1}_{\left[ {#1} \right] }}
\newcommand{\Ind}[1]{\mathbbm{1}_{\left\{ {#1} \right\} }}
\newcommand\indep{\protect\mathpalette{\protect\independenT}{\perp}}\def\independenT#1#2{\mathrel{\rlap{$#1#2$}\mkern2mu{#1#2}}}
\newcommand{\QED}{\begin{flushright} {\bf QED} \end{flushright}}
\newcommand{\R}{\mathbb R}
\newcommand{\Real}{\mathbb R}
\newcommand{\C}{\mathbb C}
\newcommand{\E}{\mathbb E}
\newcommand{\sgn}{\mathop{\mathrm{sign}}}
\def\Pr{\mathrm P}
\def\pr{\mathrm P}
\newcommand{\Var}{\mathop{\rm Var}}
\newcommand{\var}{\mathop{\rm Var}}
\newcommand{\Cov}{\mathop{\rm Cov}}
\newcommand{\cov}{\mathop{\rm Cov}}
\newcommand{\Corr}{\mathop{\rm Corr}}
\newcommand{\ang}{\mathop{\rm Angle}}
\newcommand{\tr}{\mathop{\rm trace}}
\newcommand{\proj}{\mathop{\rm Proj}}
\newcommand{\rank}{\mathop{\rm rank}}

\newcommand{\diag}{\mathop{\rm diag}}
\newcommand{\Diag}{\mathop{\rm diag}}
\newcommand{\sk}{\vspace{0.5cm}}
\newcommand{\ds}{\displaystyle}
\newcommand{\mb}{\mbox}
\newcommand{\wh}{\widehat}
\newcommand{\argmin}{\operatornamewithlimits{argmin}}
\newcommand{\argmax}{\operatornamewithlimits{argmax}}

\newcommand{\norm}[1]{\|#1\|}
\newcommand{\abs}[1]{\left\vert#1\right\vert}
\newcommand{\set}[1]{\left\{#1\right\}}

\newcommand{\To}{\longrightarrow}

\def\equalLaw{\stackrel{\mathcal{L}}{=}}
\def\equallaw{\stackrel{\mathcal{L}}{=}}

\def\half{\frac{1}{2}}

\usepackage{caption}

\begin{document}

\begin{title}
	{\Large\bf Homework 3, DATA 556: Due Tuesday, 10/16/2018}
\end{title}

\author{\bf Alexander Van Roijen}

\maketitle

\newpage
Please complete the following:
\begin{enumerate}
\item Problem 1
\begin{enumerate}
	\item Find the mean and the variance of a Discrete Uniform random variable on 1, 2, ...,n.\\
	Note that $\sum_{j=1}^{n} j = \frac{n(n+1)}{2}$ and  $\sum_{j=1}^{n} j^2 = \frac{n(n+1)(2n+1)}{6}$ are well known summations that can be proved via mathematical induction. \\ Refer to
	http://mathforum.org/library/drmath/view/56920.html
	for an example.\\
	 Let $X \sim $ DUnif
	\begin{gather}
	P(X = x) = \frac{1}{n} \text{ by the def of uniform distrib}\\
	E[X] = \sum_{j=1}^{n} P(X=j)*j = \sum_{j=1}^{n} \frac{1}{n}*j = \frac{1}{n} *\sum_{j=1}^{n} j = \frac{1}{n} * \frac{n(n+1)}{2} = \frac{n+1}{2}\\
	\text{It is a similar proof with a different subsitution for the expected value of X squared} \\
	E[X^2] = \sum_{j=1}^{n} P(X=j)*(j^2) \text{ LOTUS} \\
	= \sum_{j=1}^{n} \frac{1}{n}*(j^2) = \frac{1}{n} *\sum_{j=1}^{n} (j^2) = \frac{1}{n} * \frac{n(n+1)(2n+1)}{6} = \frac{(n+1)(2n+1)}{6}\\
	E[X^2]-(E[X])^2 = \frac{(n+1)(2n+1)}{6} - (\frac{n+1}{2})^2\\
	\frac{4*(n+1)(2n+1)}{24} - (\frac{6*(n+1)^2}{24}) = \frac{n^2-1}{12}
	\end{gather}
	\item Let X be a discrete random variable that satisfies the properties listed in the homework. Find E[X]
	\begin{gather}
		\text{We have a symmetry such that } P(X=x)=P(X=-x)\\
		E[X]= \sum_{x=-n}^{n} P(X=x)*x\\
		= P(X=-n)*-n + P(X=-(n-1))*(-(n-1)) + ... + P(X=n)*n \\
		= -1*(P(X=-n)*n - P(X=n)*n) + ... P(X=0)*0 \\
		=  -1*(P(X=n)*n - P(X=n)*n) + ... P(X=0)*0 = 0+0+...+0 \\
		\text{due to the symmetry of the probs}\\
		=> E[X] = 0
	\end{gather}
\end{enumerate}
\item We have X with PMF $P(X = k) = \frac{-1*p^k}{log(1-p)*k}$
for k = 1, 2, . . .. Here p is a parameter with 0 < p < 1. Find the mean and the variance of X
\\
First, note that the value $\frac{-1}{log(1-p)}$ is a positive constant
\begin{gather}
	E[X] = \sum_{k=1}^{\infty} P(X=k)*k = \sum_{k=1}^{\infty} \frac{-1*p^k}{log(1-p)*k} * k = \sum_{x=1}^{\infty} \frac{-1*p^k}{log(1-p)} \\ 
	= \frac{-1}{log(1-p)} \sum_{x=1}^{\infty} p^k \\
	=> \sum_{x=1}^{\infty} p^k = S => S*p = \sum_{x=2}^{\infty} p^k => S-Sp = p => S= \frac{p}{(1-p)}\\
	=> E[X] = \frac{-1}{log(1-p)} * \frac{p}{(1-p)}
	\text{similarly, the }E[X^2] \text{is proved in a similar manner except} \\
	S-Sp = \sum_{x=1}^{\infty} p^k \\
	\text{which we already proved so by substituting we get}\\
	S-Sp =  \frac{p}{(1-p)} => S = \frac{p}{(1-p)^2}\\
	=> E[X^2] = \frac{-1}{log(1-p)} * \frac{p}{(1-p)^2}\\
	=>Var(X) = E[X^2]-E[X]^2 = \frac{p(p-log(1-p))}{log(1-p)^2*(1-p)^2}
\end{gather}	
\item
\begin{enumerate}
	\item  Use LOTUS to show that for X $\sim$ Pois($\lambda$) and any function g(.), $E[Xg(X)] = \lambda E[g(X+1)]$
	\begin{gather}
		E[Xg(X)] = \sum_{x=0}^{\infty} x*g(x) \frac{e^{-\lambda} * \lambda ^ x}{x!} = \sum_{x=1}^{\infty} g(x)*\lambda \frac{e^{-\lambda} * \lambda ^{x-1}}{(x-1)!} \\
		\text{now let there be a substitution such that j = x-1}\\
		= \sum_{j=0}^{\infty} g(j+1)*\lambda \frac{e^{-\lambda} * \lambda ^{j}}{j!} =  \lambda * \sum_{j=0}^{\infty} g(j+1) \frac{e^{-\lambda} * \lambda ^{j}}{j!} \\
		\text{We see how we can convert this back to a form we understand using LOTUS}\\
		E[Xg(X)] = \lambda * E[g(X+1)] \\
	\end{gather}
	\item Find the third moment E($X^3$) for X âˆ¼ Pois($\lambda$)
	\begin{gather}
		\text{let }g(x) = x^2
		=> E(Xg(X))=\lambda E[g(X+1)]=\lambda * E[(X+1)^2]\\
		= \lambda * E[X^2 + 2X+1] = \lambda * (E[X^2] + 2E[X] + 1) \\
		\text{using the known properties of the variance and mean of the uniform dist we get}\\
		= \lambda * (\lambda^2 + \lambda + 2\lambda + 1) = \lambda^3 + 3\lambda^2 + \lambda
	\end{gather}
\end{enumerate}
\item Show that for any events $A_1..A_n$,
$P(A_1\cap...\cap A_n) \geq \sum_{j=1}^{n} P(A_j) - n +1$\\
lets prove this through induction
\begin{gather} 
	\text{Base case, n=1:} P(A) \geq P(A) - 1 + 1 => P(A) \geq P(A)\\
	\text{Now we assume this is true for 1 ... n, NTS for n+1}\\
	\text{n+1 case:} \text{we have} \sum_{j=1}^{n+1} P(A_j) -(n+1) +1 = \sum_{j=1}^{n} P(A_j) + P(A_{n+1}) - (n+1) + 1\\
	\text{Now notice we can rewrite} P(A_1 \cap .. \cap A_{n+1}) = P(B\cap A_{n+1}) \text{where} B=A_1\cap ... \cap A_n\\
	=> P(B \cap A_{n+1}) = P(B) + P(A_{n+1}) - P(A_{n+1} \cup B) \text{by definition}\\
	\text{By the induction hypothesis, we know} P(B) \geq \sum_{j=1}^{n} P(A_j) - n + 1\\
	\text{That means all that is left to show is} P(A_{n+1}) - P(A_{n+1} \cup B) \geq  P(A_{n+1}) - 1\\
	=>P(A_{n+1}) - P(A_{n+1} \cup B) \geq  P(A_{n+1}) - 1 => -P(A_{n+1} \cup B) \geq - 1 => P(A_{n+1} \cup B) \leq 1 \\
	\text{We know this inequality is true as } 0 \leq P(X) \leq 1\\
	\text{Thus, we have proved the induction step}. \square
\end{gather}

\item For X $\sim$ Pois($\lambda$), find $E[2^X]$ , if it is finite.
\begin{gather} 
	E[2^X] =\sum_{n=0}^{\infty} \frac{2^n e^{-\lambda} \lambda ^n}{n!} = \sum_{n=0}^{\infty} \frac{e^{-\lambda} (2*\lambda) ^n}{n!} = e^{-\lambda}  \sum_{n=0}^{\infty} \frac{(2*\lambda) ^n}{n!}\\
	\text{now let } \lambda' = 2*\lambda => e^{-\lambda}  \sum_{n=0}^{\infty} \frac{(\lambda') ^n}{n!}\\
	\text{we recognize this is the taylor expansion of the exponential function}\\
	\text{we get} \sum_{n=0}^{\infty} \frac{(\lambda') ^n}{n!} = e^{\lambda'} = e^{2\lambda}  => E[2^X] = e^{-\lambda} e^{2\lambda}  = e^{\lambda} \square
\end{gather}
\item For X $\sim$ Geom(p), find $E[2^X]$ and $E[2^{-X}]$ (if it is finite).
\begin{gather} 
E[2^X] =\sum_{n=1}^{\infty} 2^n (1-p)^{n-1}*p \text{ let} S = \sum_{n=1}^{\infty} 2^n (1-p)^{n-1} = 2 + 4(1-p) +... \\
=>S*2(1-p) = 4(1-p) + 8(1-p)^2 + .. => S-S*2(1-p) = 2\\
S-2S+2Sp = -S+2Sp = S(-1 + 2p) = 2 => S = \frac{2}{2p-1} =>E[2^X]=p*S = \frac{2p}{2p-1} \\
\text{Similarly  }
E[2^{-X}] = \sum_{n=1}^{\infty} 2^{-n} (1-p)^{n-1}*p \text{ we let} S =\sum_{n=1}^{\infty} 2^{-n} (1-p)^{n-1} = \sum_{n=1}^{\infty} \frac{(1-p)^{n-1}}{2^n}\\
= \frac{(1-p)^{0}}{2^1} + \frac{(1-p)^{1}}{2^2} + ... => S*\frac{1-p}{2} = \frac{(1-p)^{1}}{2^2} + \frac{(1-p)^{2}}{2^3} \\
=> S-S*\frac{1-p}{2} = S(1-\frac{1-p}{2}) = S * \frac{1+p}{2} = \frac{1}{2} => S = \frac{1}{1+p}\\
=> E[2^{-X}] = \frac{p}{1+p} \square
\end{gather}
\end{enumerate}

\end{document}
